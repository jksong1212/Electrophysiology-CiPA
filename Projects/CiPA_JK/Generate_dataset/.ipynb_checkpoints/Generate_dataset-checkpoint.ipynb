{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c797b0f5-b635-44ed-8047-735d4a931ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, copy\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import myokit\n",
    "sys.path.append('../../../')\n",
    "sys.path.append('../../../Protocols')\n",
    "sys.path.append('../../../Models')\n",
    "sys.path.append('../../../Lib')\n",
    "import protocol_lib\n",
    "import mod_trace\n",
    "\n",
    "import simulator_myokit\n",
    "import simulator_scipy\n",
    "import vc_protocols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "361e11a7-efa9-4b45-8831-79bbbea76792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_index(array, t):\n",
    "    \"\"\"Given an array, return the index with the value closest to t.\"\"\"\n",
    "    return (np.abs(np.array(array) - t)).argmin()\n",
    "\n",
    "def get_currents_with_constant_dt(xs, window=1, step_size=1):\n",
    "        \n",
    "    times = xs[0]\n",
    "    i_ion = xs[1]\n",
    "              \n",
    "    i_ion_window = []\n",
    "    t = 0\n",
    "    while t <= times[-1] - window:\n",
    "        start_index = find_closest_index(times, t)\n",
    "        end_index = find_closest_index(times, t + window)            \n",
    "        I_window = i_ion[start_index: end_index + 1]                                    \n",
    "        i_ion_window.append(sum(I_window)/len(I_window))            \n",
    "        t += step_size\n",
    "            \n",
    "    return i_ion_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fe95784-0e55-46da-9bcf-ee1067dde3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_types = {\n",
    "    'Endocardial' : 0,\n",
    "    'Epicardial' : 1,\n",
    "    'Mid-myocardial' : 2,\n",
    "}\n",
    "\n",
    "cell_type = 'Endocardial'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1528dae-c154-4cd7-a444-ce27305be8bc",
   "metadata": {},
   "source": [
    "### Create Voltage Protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7daddfb8-55ad-4ca1-9091-a12435f615c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The protocol is 1320 ms\n"
     ]
    }
   ],
   "source": [
    "# VC_protocol = vc_protocols.hERG_CiPA()\n",
    "# VC_protocol = vc_protocols.cav12_CiPA()\n",
    "# VC_protocol = vc_protocols.lateNav15_CiPA()\n",
    "VC_protocol = vc_protocols.leemV1_CiPA()\n",
    "\n",
    "vhold = -80 # VC_protocol.steps[0].voltage\n",
    "\n",
    "print(f'The protocol is {VC_protocol.get_voltage_change_endpoints()[-1]} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "708d8fc5-1c07-4933-a342-7be81094db9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 3.7358126640319824 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model, p, s = myokit.load(\"../../../mmt-model-files/newordherg_qNet_fixedconc-v1.mmt\")    \n",
    "sim = simulator_myokit.Simulator(model, VC_protocol, max_step=1.0, abs_tol=1e-06, rel_tol=1e-6, vhold=vhold)  # 1e-12, 1e-14  # 1e-08, 1e-10\n",
    "                \n",
    "# Control setting\n",
    "sim.model.get('ikr.D').set_rhs( 0 )\n",
    "\n",
    "params = {         \n",
    "    'cell.mode': cell_types[cell_type],\n",
    "    'setting.simType': 1,   # 0: AP   |  1: VC  \n",
    "       \n",
    "    'ikr.Temp' : 37,\n",
    "    'ikr.Kt' : 3.5e-05,\n",
    "    'ikr.Kmax' : 0,\n",
    "    'ikr.Ku' : 0,\n",
    "    'ikr.n' : 1,\n",
    "    'ikr.halfmax' : 1,    \n",
    "    'ikr.Vhalf' : 1,  \n",
    "}\n",
    "sim.set_simulation_params(params)\n",
    "\n",
    "print(\"--- %s seconds ---\"%(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "772e5d95-66ff-4e4c-bffa-72eee0aeaaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell.mode : 0\n",
      "setting.simType : 1\n",
      "ikr.Temp : 37\n",
      "ikr.Kt : 3.5e-05\n",
      "ikr.Kmax : 0\n",
      "ikr.Ku : 0\n",
      "ikr.n : 1\n",
      "ikr.halfmax : 1\n",
      "ikr.Vhalf : 1\n"
     ]
    }
   ],
   "source": [
    "for key, value in params.items():\n",
    "    print(f'{key} : {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b85c7cef-8820-4c3a-8e04-4da7067490c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dataset( gen_params, datasetNo=1):    \n",
    "    '''\n",
    "    type = 'AP' or 'I\" \n",
    "    params = {\n",
    "        'times': 1,                    \n",
    "        'log_li' : [],\n",
    "        'nData' : 10000,                         \n",
    "        'dataset_dir' :   './dataset',\n",
    "        'data_file_name' :  'current',\n",
    "        'scale' : 2,\n",
    "    }  \n",
    "    '''\n",
    "    random.seed(datasetNo * 84)\n",
    "    np.random.seed(datasetNo * 86)\n",
    "\n",
    "    print(\"-----Dataset%d generation starts.-----\"%(datasetNo))\n",
    "\n",
    "    d = None              \n",
    "    result_li = []\n",
    "    param_li = []\n",
    "    current_nData = 0\n",
    "    \n",
    "    simulation_error_count = 0\n",
    "    with tqdm(total = gen_params['nData']) as pbar:         \n",
    "        while (current_nData < gen_params['nData']):                \n",
    "            \n",
    "            conductance_rate = np.random.uniform(0, 1, 7)     \n",
    "            \n",
    "            if current_nData==0:\n",
    "                conductance_rate = np.ones(7)\n",
    "                \n",
    "            for i in range(7):\n",
    "                if conductance_rate[i] < 0.0000001:\n",
    "                    conductance_rate[i] = 0.0000001\n",
    "            \n",
    "            gfc = 1.0/conductance_rate\n",
    "            \n",
    "            gfc_li = {         \n",
    "                'ina.GNafc' : gfc[0],  \n",
    "                'inal.GNaLfc' : gfc[1],\n",
    "                'ito.Gtofc' : gfc[2],\n",
    "                'ical.PCafc' : gfc[3],\n",
    "                'ikr.GKrfc' : gfc[4],\n",
    "                'iks.GKsfc' : gfc[5],\n",
    "                'ik1.GK1fc' : gfc[6], \n",
    "            }\n",
    "            sim.set_simulation_params(gfc_li)             \n",
    "            \n",
    "            # log_li = ['membrane.V']\n",
    "            # if len(log_li)>0:\n",
    "            #     log_li = gen_params['log_li']\n",
    "            try :                \n",
    "                sim.pre_simulate(5000, sim_type=1)\n",
    "                d = sim.simulate( gen_params['end_time'], extra_log=gen_params['log_li'])                           \n",
    "\n",
    "                # temp = [d['engine.time']]\n",
    "                # for log in gen_params['save_log_li'] :                                              \n",
    "                #     temp.append(d[log])                 \n",
    "                # temp = get_currents_with_constant_dt(temp, window=gen_params['window'], step_size=gen_params['step_size'])\n",
    "\n",
    "                temp = [d['engine.time'], d['membrane.i_ion']]                                \n",
    "\n",
    "                if (gen_params['window']>0) and (gen_params['step_size']>0):\n",
    "                    temp = get_currents_with_constant_dt(temp, window=gen_params['window'], step_size=gen_params['step_size'])\n",
    "                    result_li.append( np.array(temp) )\n",
    "                else:\n",
    "                    result_li.append( temp )                                \n",
    "\n",
    "                param_li.append( conductance_rate )\n",
    "                current_nData+=1                    \n",
    "\n",
    "            except :\n",
    "                simulation_error_count += 1\n",
    "                print(\"There is a simulation error.\")\n",
    "                continue\n",
    "            \n",
    "            pbar.update(1) \n",
    "        \n",
    "    if gen_params['window'] != None and gen_params['step_size']:\n",
    "        result_li = np.array(result_li)        \n",
    "    else:\n",
    "        result_li = np.array(result_li, dtype=object)        \n",
    "    \n",
    "    param_li = np.array(param_li)    \n",
    "        \n",
    "    np.save(os.path.join(gen_params['dataset_dir'], f\"{gen_params['data_file_name']}{datasetNo}\" ) , result_li)\n",
    "    np.save(os.path.join(gen_params['dataset_dir'], f'parameter{datasetNo}' ), param_li )\n",
    "\n",
    "    result_li = []\n",
    "    param_li = []\n",
    "\n",
    "    print(\"=====Dataset%d generation End.  &  %d simulation errors occured.=====\"%(datasetNo, simulation_error_count))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfdcc3df-95d1-4d49-90df-869a6ad17c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of process : 70\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70]\n",
      "The folder already exists.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Dataset1 generation starts.----------Dataset4 generation starts.----------Dataset5 generation starts.----------Dataset3 generation starts.----------Dataset2 generation starts.----------Dataset6 generation starts.----------Dataset7 generation starts.----------Dataset9 generation starts.----------Dataset10 generation starts.----------Dataset8 generation starts.----------Dataset11 generation starts.----------Dataset12 generation starts.----------Dataset13 generation starts.----------Dataset14 generation starts.----------Dataset15 generation starts.----------Dataset16 generation starts.----------Dataset21 generation starts.----------Dataset17 generation starts.----------Dataset18 generation starts.-----\n",
      "-----Dataset20 generation starts.----------Dataset23 generation starts.----------Dataset19 generation starts.-----\n",
      "\n",
      "\n",
      "-----Dataset22 generation starts.----------Dataset24 generation starts.-----\n",
      "-----Dataset25 generation starts.-----\n",
      "\n",
      "\n",
      "-----Dataset26 generation starts.----------Dataset27 generation starts.----------Dataset28 generation starts.-----\n",
      "\n",
      "\n",
      "\n",
      "-----Dataset34 generation starts.----------Dataset29 generation starts.----------Dataset30 generation starts.----------Dataset31 generation starts.----------Dataset37 generation starts.----------Dataset32 generation starts.----------Dataset38 generation starts.----------Dataset39 generation starts.-----\n",
      "-----Dataset36 generation starts.-----\n",
      "-----Dataset33 generation starts.-----\n",
      "\n",
      "-----Dataset42 generation starts.----------Dataset35 generation starts.-----\n",
      "\n",
      "-----Dataset41 generation starts.----------Dataset43 generation starts.----------Dataset40 generation starts.-----\n",
      "-----Dataset47 generation starts.----------Dataset44 generation starts.----------Dataset45 generation starts.----------Dataset48 generation starts.-----\n",
      "-----Dataset51 generation starts.-----\n",
      "-----Dataset52 generation starts.----------Dataset50 generation starts.----------Dataset49 generation starts.-----\n",
      "-----Dataset55 generation starts.----------Dataset53 generation starts.----------Dataset46 generation starts.----------Dataset54 generation starts.----------Dataset58 generation starts.----------Dataset61 generation starts.----------Dataset57 generation starts.----------Dataset59 generation starts.-----\n",
      "-----Dataset60 generation starts.----------Dataset56 generation starts.-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----Dataset65 generation starts.----------Dataset67 generation starts.----------Dataset66 generation starts.----------Dataset69 generation starts.----------Dataset68 generation starts.-----"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Dataset70 generation starts.-----"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Dataset62 generation starts.----------Dataset63 generation starts.-----\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Dataset64 generation starts.-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████▌                           | 2770/10000 [05:25<12:53,  9.35it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 30%|███████████▌                          | 3047/10000 [05:58<12:43,  9.10it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 32%|████████████▏                         | 3204/10000 [06:10<12:04,  9.38it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 33%|████████████▍                         | 3281/10000 [06:18<12:19,  9.09it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 33%|████████████▋                         | 3344/10000 [06:25<11:39,  9.52it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 34%|████████████▊                         | 3369/10000 [06:30<11:46,  9.38it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 34%|████████████▉                         | 3408/10000 [06:33<11:36,  9.46it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 34%|████████████▊                         | 3385/10000 [06:38<12:08,  9.08it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 49%|██████████████████▋                   | 4923/10000 [09:26<09:06,  9.29it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 49%|██████████████████▌                   | 4897/10000 [09:34<10:29,  8.11it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 49%|██████████████████▊                   | 4942/10000 [09:42<09:54,  8.51it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 50%|███████████████████                   | 5015/10000 [09:49<09:09,  9.07it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 51%|███████████████████▎                  | 5090/10000 [09:57<09:08,  8.95it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 52%|███████████████████▉                  | 5238/10000 [10:04<09:16,  8.56it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 85%|████████████████████████████████▎     | 8502/10000 [16:23<02:49,  8.85it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 85%|████████████████████████████████▎     | 8487/10000 [16:31<03:10,  7.94it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 89%|█████████████████████████████████▊    | 8897/10000 [17:06<01:58,  9.32it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 88%|█████████████████████████████████▌    | 8847/10000 [17:15<02:07,  9.03it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 90%|██████████████████████████████████▎   | 9034/10000 [17:25<01:51,  8.67it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 91%|██████████████████████████████████▋   | 9140/10000 [17:33<01:34,  9.10it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 92%|██████████████████████████████████▉   | 9184/10000 [17:40<01:31,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Dataset28 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset13 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset64 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset12 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset26 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset56 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset20 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset10 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset3 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset32 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset2 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset38 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset33 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset19 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset1 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset44 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset22 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset70 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset34 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset45 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset63 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset35 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset17 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset49 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset69 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset11 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset6 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset53 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset31 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset55 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset60 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset18 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset51 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset65 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset39 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset23 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset5 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset30 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset27 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset9 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset36 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset29 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset14 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset42 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset15 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset47 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset62 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset50 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset58 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset52 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset37 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset67 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset8 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset21 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset41 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset48 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset4 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset66 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset40 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset54 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset68 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset57 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset43 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset25 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset46 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset7 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset61 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset16 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset59 generation End.  &  0 simulation errors occured.=====\n",
      "=====Dataset24 generation End.  &  0 simulation errors occured.=====\n",
      "--- 1369.9067947864532 seconds ---\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    start_time = time.time()    \n",
    "    nCPU = os.cpu_count()      \n",
    "    nCPU = 70\n",
    "    print(\"The number of process :\", nCPU )   \n",
    "   \n",
    "    multi = True\n",
    "    \n",
    "    gen_params = {\n",
    "        'end_time': VC_protocol.get_voltage_change_endpoints()[-1],                            \n",
    "        'log_li' : ['membrane.i_ion'],\n",
    "        'save_log_li' : ['membrane.i_ion'],\n",
    "        'nData' : 10000,                         \n",
    "        'dataset_dir' : f'./newordherg_qNet_fixedconc_v1_LeemV1_{cell_type}_tGr',\n",
    "        'data_file_name' : 'currents',\n",
    "        'window' : 0,\n",
    "        'step_size' : 0,\n",
    "        'startNo' : 1,\n",
    "        'nDataset' : 70,\n",
    "    }  \n",
    "    gen_params['dataset_dir'] = gen_params['dataset_dir'] #+ f\"_w{gen_params['window']}_s{gen_params['step_size']}\"\n",
    "\n",
    "    datasetNo_li = list(range(gen_params['startNo'], gen_params['startNo']+gen_params['nDataset']))  # Core 수만큼  [1,2,3,4,5,6,7,8,9,10]    \n",
    "    print(datasetNo_li)          \n",
    "        \n",
    "    try:\n",
    "        if not os.path.exists(gen_params['dataset_dir']):\n",
    "            os.makedirs(gen_params['dataset_dir'])\n",
    "            print('\"%s\" has been created.'%(gen_params['dataset_dir']))\n",
    "        else:\n",
    "            print(\"The folder already exists.\")\n",
    "    except OSError:\n",
    "        print('Error: create_folder(). : ' + gen_params['dataset_dir'])\n",
    "        \n",
    "    \n",
    "    '''\n",
    "    Plot\n",
    "    '''\n",
    "    fig, ax = plt.subplots(1,1, figsize=(10,3))    \n",
    "    # fig.suptitle(sim.name, fontsize=14)\n",
    "    # ax.set_title('Simulation %d'%(simulationNo))\n",
    "    # axes[i].set_xlim(model_scipy.times.min(), model_scipy.times.max())\n",
    "    # ax.set_ylim(ylim[0], ylim[1])\n",
    "    ax.set_xlabel('Time (ms)')       \n",
    "    ax.set_ylabel(f'Voltage')      \n",
    "    times = np.linspace(0, VC_protocol.get_voltage_change_endpoints()[-1], 10000)  \n",
    "    ax.plot( times, VC_protocol.get_voltage_clamp_protocol(times), label='VC', color='k', linewidth=5)     \n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    # ax[-1].set_ylim(-5, 5)\n",
    "\n",
    "    plt.subplots_adjust(left=0.07, bottom=0.05, right=0.95, top=0.95, wspace=0.5, hspace=0.15)\n",
    "    plt.show()\n",
    "    fig.savefig(os.path.join(gen_params['dataset_dir'], \"aVC.jpg\" ), dpi=100)\n",
    "        \n",
    "    if multi :            \n",
    "        pool = multiprocessing.Pool(processes=nCPU )\n",
    "        func = partial(gen_dataset, gen_params)\n",
    "        pool.map(func, datasetNo_li)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    else:\n",
    "        for No in datasetNo_li :\n",
    "            gen_dataset(gen_params, No)\n",
    "        \n",
    "    # print(\"Dataset has been generated.\")\n",
    "    \n",
    "    print(\"--- %s seconds ---\"%(time.time()-start_time))\n",
    "    \n",
    "    # \n",
    "\n",
    "    # # Set parameter transformation\n",
    "    # transform_to_model_param = log_transform_to_model_param       # return np.exp(out)\n",
    "    # transform_from_model_param = log_transform_from_model_param   # return np.log(out)\n",
    "    \n",
    "    # logprior = LogPrior(transform_to_model_param, transform_from_model_param)\n",
    "      \n",
    "    # p = logprior.sample_without_inv_transform()\n",
    "    # print(p)\n",
    "    \n",
    "    # print(logprior.rmax)\n",
    "    # print(logprior.rmin)\n",
    "    # print(5e5)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7e984b5-0794-4eae-98a0-bec0f6b4b033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish\n"
     ]
    }
   ],
   "source": [
    "print(\"Finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8128a932-2d15-479e-a3d3-7c9d6b0ec475",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
